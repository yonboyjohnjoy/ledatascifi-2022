{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical significance\n",
    "\n",
    "[Previously,](02b_mechanics.html#including-interaction-terms) we estimated \n",
    "\n",
    "$$\n",
    "\\log(\\text{price})= 8.2+ 1.53 *\\log(\\text{carat}) + 0.33* \\text{Ideal} + 0.18* \\log(\\text{carat})\\cdot \\text{Ideal}\n",
    "$$\n",
    "\n",
    "Those coefficients are _estimates_, not gospel. There is some uncertainty about what the \"true\" value should be.\n",
    "```{margin}\n",
    "<img src=https://media.giphy.com/media/TIjVQiwWQFDMzjk4gU/giphy.gif width=\"150\">\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-input",
     "hide-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>lprice</td>      <th>  R-squared:         </th> <td>   0.930</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.930</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>1.022e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 25 Mar 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:42:05</td>     <th>  Log-Likelihood:    </th> <td> -1650.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 23106</td>      <th>  AIC:               </th> <td>   3310.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 23102</td>      <th>  BIC:               </th> <td>   3342.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>            <td>    8.1954</td> <td>    0.007</td> <td> 1232.871</td> <td> 0.000</td> <td>    8.182</td> <td>    8.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ideal[T.True]</th>        <td>    0.3302</td> <td>    0.007</td> <td>   46.677</td> <td> 0.000</td> <td>    0.316</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lcarat</th>               <td>    1.5282</td> <td>    0.015</td> <td>  103.832</td> <td> 0.000</td> <td>    1.499</td> <td>    1.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lcarat:ideal[T.True]</th> <td>    0.1822</td> <td>    0.015</td> <td>   12.101</td> <td> 0.000</td> <td>    0.153</td> <td>    0.212</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>117.253</td> <th>  Durbin-Watson:     </th> <td>   1.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 145.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.097</td>  <th>  Prob(JB):          </th> <td>2.58e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.337</td>  <th>  Cond. No.          </th> <td>    19.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 lprice   R-squared:                       0.930\n",
       "Model:                            OLS   Adj. R-squared:                  0.930\n",
       "Method:                 Least Squares   F-statistic:                 1.022e+05\n",
       "Date:                Thu, 25 Mar 2021   Prob (F-statistic):               0.00\n",
       "Time:                        14:42:05   Log-Likelihood:                -1650.8\n",
       "No. Observations:               23106   AIC:                             3310.\n",
       "Df Residuals:                   23102   BIC:                             3342.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "Intercept                8.1954      0.007   1232.871      0.000       8.182       8.208\n",
       "ideal[T.True]            0.3302      0.007     46.677      0.000       0.316       0.344\n",
       "lcarat                   1.5282      0.015    103.832      0.000       1.499       1.557\n",
       "lcarat:ideal[T.True]     0.1822      0.015     12.101      0.000       0.153       0.212\n",
       "==============================================================================\n",
       "Omnibus:                      117.253   Durbin-Watson:                   1.231\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              145.473\n",
       "Skew:                           0.097   Prob(JB):                     2.58e-32\n",
       "Kurtosis:                       3.337   Cond. No.                         19.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load some data to practice regressions\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statsmodels.formula.api import ols as sm_ols # need this\n",
    "\n",
    "diamonds = sns.load_dataset('diamonds')\n",
    "\n",
    "# this alteration is not strictly necessary to practice a regression\n",
    "# but we use this in livecoding\n",
    "diamonds2 = (diamonds.query('carat < 2.5')               # censor/remove outliers\n",
    "            .assign(lprice = np.log(diamonds['price']))  # log transform price\n",
    "            .assign(lcarat = np.log(diamonds['carat']))  # log transform carats\n",
    "            .assign(ideal = diamonds['cut'] == 'Ideal') \n",
    "             \n",
    "             # some regression packages want you to explicitly provide \n",
    "             # a variable for the constant\n",
    "            .assign(const = 1)                           \n",
    "            )  \n",
    "\n",
    "sm_ols('lprice ~ lcarat + ideal + lcarat*ideal', data=diamonds2.query('cut in [\"Fair\",\"Ideal\"]')).fit().summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the resulting table (which you can see above) displays information next to each coefficient about the level of precision associated with the estimated coefficients.\n",
    "\n",
    "| Column | Meaning |\n",
    "| :-- | :-- |\n",
    "| \"std err\" |\tThe standard error of the coefficient estimate |\n",
    "| \"t\" \t    |  The _**\"t-stat\"**_ = $\\beta$ divided by its standard error |\n",
    "| \"P>t\" \t|  The _**\"p-value\"**_ is the probability that the coefficient is different than zero by random chance. |\n",
    "| \"[0.025 \t0.975]\" | The 95% confidence interval for the coefficient. | \n",
    "\n",
    "\n",
    "```{note}\n",
    "We use these columns, particularly the \"t-stat\" and \"p-value\", to assess the probability that the coefficient is different than zero by random chance. \n",
    "- A t-stat of 1.645 corresponds to a p-value of 0.10; meaning only 10% of the time would you get that coefficient randomly\n",
    "- A t-stat of 1.96 corresponds to a p-value of 0.05; this is a common \"threshold\" to say a \"relationship is _**statistically**_ significant\" and that \"the relationship between X and y is not zero\"\n",
    "- A t-stat of 2.58 corresponds to a p-value of 0.01\n",
    "```\n",
    "\n",
    "The \"classical\" approach to assess whether X is related to y is to see if the t-stat on X is above 1.96. These thresholds are important and part of a sensible approach to learning from data, but...\n",
    "\n",
    "When people say a \"relationship is statistically significant\", what they often mean is \n",
    "<br>\n",
    "<center>\"LOOK YONDER, I HAVE FOUND A NEW, MEANINGFUL  <br>\n",
    "    CORRELATION THAT IS TRUE <br> (TRULY!) (VERILY!)  <br>\n",
    "    AND KNOWING IT ... <br> WILL CHANGE THE WORLD!\"</center>\n",
    "\n",
    "Which leads me to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Significant_ warnings about \"statistical significance\"\n",
    "\n",
    "The focus on t-stats p-values can be dangerous. As it turns out, \"p-hacking\" (finding a significant relationship) is easy for a number of reasons:\n",
    "- If you look at enough Xs and enough ys, you, by chance alone, can find \"significant\" relationships where [none exist](https://www.tylervigen.com/spurious-correlations )\n",
    "- Your data can be biased. [Dewey Defeats Truman](https://en.wikipedia.org/wiki/Dewey_Defeats_Truman) may be the most famous example\n",
    "    <img src=https://upload.wikimedia.org/wikipedia/en/2/28/Deweytruman12.jpg width=\"400\">\n",
    "    \n",
    "- Your sample restrictions can generate bias: If you evaluate the trading strategy \"buy and hold current S&P companies\" for the last 50 years, you'll discover that this trading strategy was unbelievable!\n",
    "- Reusing the data: If you torture the data, it will confess!\n",
    "\n",
    "\n",
    "```{admonition} Torturing your data\n",
    ":class: warning\n",
    "There is a [fun game in here](https://fivethirtyeight.com/features/science-isnt-broken/#part1). \n",
    "\n",
    "The point: \n",
    "1. The choices you make about what variables to include or focus on can change the _statistical_ results. \n",
    "2. **And if you play with a dataset long enough, you'll find \"results\"... ***\n",
    "```\n",
    "\n",
    "### The focus on p-values can be dangerous because it distorts the incentives of researchers\n",
    "\n",
    "- Again: **If you torture the data, it will confess (regardless of whether you or it wanted to)**\n",
    "- **Motivated reasoning/cognitive dissonance/confirmation bias**: Analysis like [the game above](https://fivethirtyeight.com/features/science-isnt-broken/#part1) is fraught with temptations for humans. That 538 article mentions that about 2/3 of retractions are due to misconduct.\n",
    "- Focus on p-value **shifts attention: Statistical signicance does not mean causation nor economic significance (i.e. large/important relationships)**\n",
    "\n",
    "```{admonition} Tips to avoid p-hacking\n",
    ":class: tips\n",
    "1. Your focus should be on testing and evaluating a hypothesis, not \"finding a result\"\n",
    "1. Null results are fine!    Famously, Edison and his teams found a lot of wire filaments that did _not_ work for a lightbulb, and this information was valuable!\n",
    "1. \"Preregister\" your ideas\n",
    "    - The simplest version of this: Write down your data, theory, and hypothesis (it can be short!) **BEFORE** you run your tests.\n",
    "    - [This Science article](https://www.sciencemag.org/news/2018/09/more-and-more-scientists-are-preregistering-their-studies-should-you) covers the reasoning and intuition for it\n",
    "    - [This article by Brian Nosek, one of the key voices pushing for ways to improve credibility](https://www.pnas.org/content/115/11/2600) is an instant classic\n",
    "```\n",
    "\n",
    "### Common analytical errors\n",
    "\n",
    "Let me repost this figure from [an earlier page](01a_MLgonewrong). Notice how a focus on finding significant results can incentivize or subtly lead you towards several of these:\n",
    "\n",
    "```{image} img/data_fallacies_to_avoid.jpg\n",
    ":alt: flowchart\n",
    ":width: 800px\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
