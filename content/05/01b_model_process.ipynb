{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The modeling process\n",
    "\n",
    "<p style=\"font-size:2em\"> Or: How to define a project and structure the process </p> \n",
    "\n",
    "\n",
    "```{admonition} Summary\n",
    "1. Start with an interesting question or problem\n",
    "2. [What type of question are you asking?](#what-type-of-question-are-you-asking)\n",
    "3. Think about data:\n",
    "    - What is the ideal dataset that would most easily answer your question?\n",
    "    - What data is available (sources, how easy/costly is it to get)\n",
    "    - Explore the data. \n",
    "    - If you have sub-optimal data, you'll have to adjust your subsequent steps to use that data. Adjustments are a natural part of the modeling cycle.\n",
    "4. [Pick your model(s)](#pick-your-model-s)\n",
    "5. Estimate your model(s) and evaluate the output\n",
    "```\n",
    "\n",
    "Modeling is NOT typing `import sklearn` and plowing into the data like Leroy Jenkins. Throughout the semester, you've seen that thinking about how to code a solution to a homework problem is usually easiest when you step back, and think about the challenge you're facing, and writing down some pseudocode. \n",
    "\n",
    "Modeling (applying data science techniques to our finance problems) is that on steroids. Instead of needing to figure out how to writing code to solve a discrete problem (reshape the data to our analysis level, add a variable to our dataset), we need _to figure out what to do._\n",
    "\n",
    "---\n",
    "\n",
    "```{epigraph}\n",
    "A few times a year, I get asked to be a judge of student statistical projects in politics or sports. While the students are very bright, **they spend WAY too much time using fancy statistical methods and not enough time framing the right questions and contextualizing their answers.** If you want to be a good data scientist, you should spend ~49% of your time developing your statistical intuition (i.e. how to ask good questions of the data), and ~49% of your time on domain knowledge (improving overall understanding of your field). **Only ~2% on methods per se.** \n",
    "\n",
    "-- Nate Silver\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "So, we will build up the requisite skills to do the mechanical stuff, but honestly, most interesting applied problems don't hinge on the ability to type `knn.fit(y,X)`. It's all the stuff around it, that led you to the dataset you have, and how you're using it to estimate some model, and how you'll use the estimated model. \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "## What type of question are you asking?\n",
    "\n",
    "Most analyses fall into one of two camps, based on the type of question:\n",
    "\n",
    "```{tabbed} 1. **Questions about RELATIONSHIPS between variables**\n",
    "Example: Do airline closures affect how VCs monitor portfolio companies? \n",
    "- Direction matters: Is the relationship _positive, negative, or neither?_ \n",
    "- Magnitude of the relationship usually matters (which factors matter most?)\n",
    "- Is the relationship because one causes the other, or is it a correlation reflecting something else?\n",
    "\n",
    "Model: You'll probably start with regression or logit\n",
    "```\n",
    "\n",
    "```{tabbed} 1. 2. **Questions about PREDICTING some outcome variable**\n",
    "Example: Which loans will default? \n",
    "- Which factors matter and by how much, and in what ways are not as important\n",
    "\n",
    "Model: Probably something more complex (depends on question)\n",
    "```\n",
    "\n",
    "## Why should I think about the type of question?\n",
    "\n",
    "The type of question is a good thing to fix in your head, because it dictates what you care about when you pick and estimate your models. \n",
    "1. Suppose you have two variables, $y$ and $X$.\n",
    "1. You run a regression on it. That regression models the data as $y = m+\\beta*X$. \n",
    "1. The regression produces an estimate for m and $\\beta$, and I'll call the estimates versions $\\hat{m}$ and $\\hat{\\beta}$. (I add the hats to denote that these are estimates, and because choosing weird notation to confuse undergrads is in all faculty contracts.)\n",
    "1. You can also use the estimates to create predicted values for y, which I'll call $\\hat{y}$ and the formula to get them is $\\hat{y}=\\hat{m}+\\hat{\\beta}*X$. That is, you take all the _**real**_ values of X, and multiply by $\\hat{\\beta}$, and then add $\\hat{m}$.\n",
    "\n",
    "So, do you care about $\\hat{\\beta}$, or $\\hat{y}$? It depends on the type of your question!\n",
    "\n",
    "```{tip}\n",
    "- Relationship questions are $\\hat{\\beta}$ questions\n",
    "- Prediction questions are $\\hat{y}$ questions\n",
    "```\n",
    "\n",
    "## Pick your model(s) \n",
    "\n",
    "```{admonition} **A model is an idealized representation of a system**\n",
    "\n",
    "For example:\n",
    "- $E=mc^2$\n",
    "- Financing policies: $investment = MarginalQ$\n",
    "- Asset prices: $r = \\beta * MKT$\n",
    "\n",
    "Famous take by George Box: \"All models are wrong, but some are useful\"\n",
    "\n",
    "```\n",
    "\n",
    "| | Relationship model | Prediction model |\n",
    "| :--- | :--- | :--- |\n",
    "| Word example | When people have one ice cream cone, they are 2% more likely to drown | Loan defaults over the next three months will be 9% for restaurant and service workers |\n",
    "| Model/Data | Model should summarize the data | May not summarize the data, and often are impossible to interpret beyond predicted values |\n",
    "| Complexity | Simpler models are often preferred  because they are easier to interpret | More complex models are often favored (understanding how predictions are made is less important than accuracy | \n",
    "| Example | Linear regression: $final grade = b + m * midterm grade$ | Nearest neighbor model: $final grade = nearest neighbor(midterm grade)$ |\n",
    "\n",
    "## Estimate your model\n",
    "\n",
    "We will talk in depth about a few models in class, but generally, these three steps always apply: \n",
    "1. Select a model. (For example: find the \"center\" of a univariate distribution, regression, logistic)\n",
    "    - Use knowledge about the domain area of the question to help pick the model\n",
    "2. Select a loss function. (For example: Mean squared error, mean absolute deviation, R2)\n",
    "    - There are many loss functions!\n",
    "    - The loss function choice affects the accuracy and speed of estimation\n",
    "    - Choice depends on the estimation task\n",
    "    - Qualitative or quantitative data?\n",
    "    - Are all errors equal? (A false negative on a cancer test is much worse than a false positive!)\n",
    "    - Do outliers matter more or less? \n",
    "    - Some models often imply the loss function. For example, regression's loss function is almost always Mean Squared Error. \n",
    "3. Estimate (\"fit\") the model by minimizing the loss.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
